<!DOCTYPE html>
        <html>
        <style>
        img {
            float: right;
        }
        img.one {
            height: auto;
            width: auto;
        }
        </style>
        <body>
        <h4>HyperParams</h4>
        <table><img src="./acc1.png" alt="Accuracy plots" width="80%" height="auto" style="margin-left:15px;">
        <tr>
            <th>Param</th><th>Value</th>
        </tr><tr><td>src </td><td> amazon</td></tr><tr><td>tar </td><td> webcam</td></tr><tr><td>manual_seed </td><td> 1</td></tr><tr><td>batchSize </td><td> 32</td></tr><tr><td>use_gpu </td><td> True</td></tr><tr><td>num_classes </td><td> 31</td></tr><tr><td>epochs </td><td> 1000</td></tr><tr><td>momentum </td><td> 0.9</td></tr><tr><td>lr </td><td> 0.0002</td></tr><tr><td>lr_sch </td><td> No</td></tr><tr><td>lr_sch_gamma </td><td> 0.1</td></tr><tr><td>p_lr_decay </td><td> 1000</td></tr><tr><td>n0 </td><td> 1.0</td></tr><tr><td>alpha </td><td> 10</td></tr><tr><td>beta </td><td> 0.75</td></tr><tr><td>betas </td><td> (0.5, 0.99)</td></tr><tr><td>net_wtDcy </td><td> 0.0001</td></tr><tr><td>net_biasDcy </td><td> 0.0</td></tr><tr><td>net_wtLR </td><td> 1</td></tr><tr><td>net_biasLR </td><td> 2</td></tr><tr><td>btl_wtDcy </td><td> 0.0001</td></tr><tr><td>btl_biasDcy </td><td> 0.0</td></tr><tr><td>btl_wtLR </td><td> 10</td></tr><tr><td>btl_biasLR </td><td> 20</td></tr><tr><td>srcDataLen </td><td> 2817</td></tr><tr><td>tarDataLen </td><td> 795</td></tr></table>
<h4>Classifier Network</h4>Model(
  (classifier): Sequential(
    (0): Linear(in_features=4096, out_features=256, bias=True)
    (1): ReLU(inplace)
    (2): Linear(in_features=256, out_features=31, bias=True)
  )
)
<h4>Base Network - Alexnet</h4>VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace)
    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace)
    (9): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace)
    (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace)
    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace)
    (30): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)
  )
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace)
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace)
    (5): Dropout(p=0.5)
  )
)
<h4>Layers frozen</h4>
<span style="font-weight:bold">features.0.weight</span> False
<span style="font-weight:bold">features.0.bias</span> False
<span style="font-weight:bold">features.2.weight</span> False
<span style="font-weight:bold">features.2.bias</span> False
<span style="font-weight:bold">features.5.weight</span> False
<span style="font-weight:bold">features.5.bias</span> False
<span style="font-weight:bold">features.7.weight</span> False
<span style="font-weight:bold">features.7.bias</span> False
<span style="font-weight:bold">features.10.weight</span> False
<span style="font-weight:bold">features.10.bias</span> False
<span style="font-weight:bold">features.12.weight</span> False
<span style="font-weight:bold">features.12.bias</span> False
<span style="font-weight:bold">features.14.weight</span> False
<span style="font-weight:bold">features.14.bias</span> False
<span style="font-weight:bold">features.17.weight</span> False
<span style="font-weight:bold">features.17.bias</span> False
<span style="font-weight:bold">features.19.weight</span> True
<span style="font-weight:bold">features.19.bias</span> True
<span style="font-weight:bold">features.21.weight</span> True
<span style="font-weight:bold">features.21.bias</span> True
<span style="font-weight:bold">features.24.weight</span> True
<span style="font-weight:bold">features.24.bias</span> True
<span style="font-weight:bold">features.26.weight</span> True
<span style="font-weight:bold">features.26.bias</span> True
<span style="font-weight:bold">features.28.weight</span> True
<span style="font-weight:bold">features.28.bias</span> True
<span style="font-weight:bold">classifier.0.weight</span> True
<span style="font-weight:bold">classifier.0.bias</span> True
<span style="font-weight:bold">classifier.3.weight</span> True
<span style="font-weight:bold">classifier.3.bias</span> True
</body></html>