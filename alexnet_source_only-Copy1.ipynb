{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:42:19.040530Z",
     "start_time": "2018-04-19T11:42:19.036289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%set_env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%set_env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:42:24.371884Z",
     "start_time": "2018-04-19T11:42:20.918257Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from config import domainData\n",
    "from config import num_classes as NUM_CLASSES\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "import utils\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from alexnet import alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:42:29.058329Z",
     "start_time": "2018-04-19T11:42:28.929724Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = alexnet\n",
    "net.load_state_dict(torch.load('alexnet.pth'))\n",
    "# print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:42:29.928471Z",
     "start_time": "2018-04-19T11:42:29.918794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "  (1): ReLU(inplace)\n",
      "  (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1)\n",
      "  (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
      "  (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=2)\n",
      "  (5): ReLU(inplace)\n",
      "  (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=1)\n",
      "  (7): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
      "  (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (9): ReLU(inplace)\n",
      "  (10): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (11): ReLU(inplace)\n",
      "  (12): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
      "  (13): ReLU(inplace)\n",
      "  (14): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
      "  (15): Lambda(\n",
      "  )\n",
      "  (16): Sequential(\n",
      "    (0): Lambda(\n",
      "    )\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "  )\n",
      "  (17): ReLU(inplace)\n",
      "  (18): Dropout(p=0.5)\n",
      "  (19): Sequential(\n",
      "    (0): Lambda(\n",
      "    )\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  )\n",
      "  (20): ReLU(inplace)\n",
      "  (21): Dropout(p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(*list(net.children())[:-2])\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:42:31.650140Z",
     "start_time": "2018-04-19T11:42:31.644905Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src = domainData['amazon']\n",
    "tar = domainData['webcam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:44:34.576225Z",
     "start_time": "2018-04-19T11:44:34.564236Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_transform(x):\n",
    "    tensortype = type(x)\n",
    "    mean = tensortype(x.size())\n",
    "    mean[0, :, :] = 103.939\n",
    "    mean[1, :, :] = 116.779\n",
    "    mean[2, :, :] = 123.680\n",
    "    x = x.sub(mean) # subtract mean\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:44:35.588808Z",
     "start_time": "2018-04-19T11:44:35.568788Z"
    }
   },
   "outputs": [],
   "source": [
    "src_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "#     transforms.CenterCrop(227),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomResizedCrop(227, scale=(0.50,1.0), ratio=(1.,1.)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5,0.5,0.5),\n",
    "                        std=(0.5,0.5,0.5)),\n",
    "    transforms.Lambda(lambda x: torch.stack([x[2],x[1],x[0]])), # RGB -> BGR\n",
    "    transforms.Lambda(lambda x: (x+1.) * 255. * 0.5),\n",
    "    transforms.Lambda(gen_transform)\n",
    "                         \n",
    "])\n",
    "tar_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(227),\n",
    "#     transforms.RandomResizedCrop(224, scale=(0.25,1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[1.,1.,1.]),\n",
    "    transforms.Lambda(lambda x: torch.stack([x[2],x[1],x[0]])),\n",
    "    transforms.Lambda(lambda x: x * 255.)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:44:37.838353Z",
     "start_time": "2018-04-19T11:44:37.784878Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_dataset = datasets.ImageFolder(src, transform=src_transforms)\n",
    "tar_dataset = datasets.ImageFolder(tar, transform=tar_transforms)\n",
    "srcSampler = torch.utils.data.sampler.RandomSampler(src_dataset)\n",
    "tarSampler = torch.utils.data.sampler.RandomSampler(tar_dataset)\n",
    "srcDataLen = len(src_dataset)\n",
    "tarDataLen = len(tar_dataset)\n",
    "use_gpu = True and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:09.763146Z",
     "start_time": "2018-04-19T11:45:09.752072Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = {\n",
    "    'src': 'Amazon',\n",
    "    'tar': 'Webcam',\n",
    "    'manual_seed':1,\n",
    "    'batchSize':64,\n",
    "    'use_gpu': use_gpu,\n",
    "    'num_classes': 31,\n",
    "    'epochs': 75,\n",
    "    'momentum': 0.9,\n",
    "    'lr': 2e-4,\n",
    "    'lr_sch': 0,\n",
    "    'lr_sch_gamma': 0.1,\n",
    "    'p_lr_decay': 75,\n",
    "    'n0': 1.,\n",
    "    'alpha': 10,\n",
    "    'beta': 0.75,\n",
    "    'betas': (0.5,0.99),\n",
    "    'net_wtDcy': 0.001,\n",
    "    'btl_wtDcy': 0.001,\n",
    "    'srcDataLen': srcDataLen,\n",
    "    'tarDataLen': tarDataLen\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:12.301861Z",
     "start_time": "2018-04-19T11:45:12.288936Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(opt['manual_seed'])\n",
    "if opt['use_gpu']: torch.cuda.manual_seed(opt['manual_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:13.356294Z",
     "start_time": "2018-04-19T11:45:13.351642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_gpu:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"use_gpu: \", opt['use_gpu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:14.474853Z",
     "start_time": "2018-04-19T11:45:14.463919Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src_dataloader = torch.utils.data.DataLoader(src_dataset, batch_size=opt['batchSize'], \n",
    "                                             shuffle=(srcSampler is None), sampler=srcSampler,\n",
    "                                            num_workers=2, pin_memory=True, drop_last=False)\n",
    "tar_dataloader = torch.utils.data.DataLoader(tar_dataset, batch_size=opt['batchSize'],\n",
    "                                            shuffle=(tarSampler is None), sampler=tarSampler,\n",
    "                                            num_workers=2, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:15.609362Z",
     "start_time": "2018-04-19T11:45:15.604133Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "#     print(m)\n",
    "    if isinstance(m, nn.Linear):\n",
    "        init.xavier_normal(m.weight)\n",
    "        init.constant(m.bias, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:16.437588Z",
     "start_time": "2018-04-19T11:45:16.424589Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.classifier = nn.Sequential(nn.Linear(4096,256),\n",
    "                                       nn.ReLU(inplace=True), nn.Linear(256, opt['num_classes']))\n",
    "        self.classifier.apply(init_weights)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:17.418308Z",
     "start_time": "2018-04-19T11:45:17.199168Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2 = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:21.580462Z",
     "start_time": "2018-04-19T11:45:18.317482Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if opt['use_gpu']:\n",
    "    net = net.cuda()\n",
    "    net2 = net2.cuda()\n",
    "    torch.backends.cudnn.enabled=True\n",
    "    torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To computer norm of various parameters\n",
    "\n",
    "```python\n",
    "for name, param in net2.named_parameters():\n",
    "    nrm = torch.norm(param, 2)\n",
    "    zero = param.eq(0.).float().sum()\n",
    "    nele = torch.numel(param)\n",
    "    print(name, nrm.data[0], nele, zero.data[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:24.392910Z",
     "start_time": "2018-04-19T11:45:24.389030Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:25.223929Z",
     "start_time": "2018-04-19T11:45:25.216114Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netfeatwt, netfeatbias = list(), list()\n",
    "for name, param in net.named_parameters():\n",
    "    if name in ['10.weight', '12.weight', '16.1.weight', '19.1.weight']: netfeatwt.append(param)\n",
    "    elif name in ['10.bias', '12.bias', '16.1.bias', '19.1.bias']: netfeatbias.append(param)\n",
    "    else: param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:26.413851Z",
     "start_time": "2018-04-19T11:45:26.403657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight False\n",
      "0.bias False\n",
      "4.weight False\n",
      "4.bias False\n",
      "8.weight False\n",
      "8.bias False\n",
      "10.weight True\n",
      "10.bias True\n",
      "12.weight True\n",
      "12.bias True\n",
      "16.1.weight True\n",
      "16.1.bias True\n",
      "19.1.weight True\n",
      "19.1.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:28.215966Z",
     "start_time": "2018-04-19T11:45:28.210108Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net2_weight, net2_bias = list(), list()\n",
    "for name, param in net2.named_parameters():\n",
    "    if 'weight' in name: net2_weight.append(param)\n",
    "    elif 'bias' in name: net2_bias.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:29.157493Z",
     "start_time": "2018-04-19T11:45:29.124247Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_params = [\n",
    "    {'params': netfeatwt, 'lr': opt['lr'], 'momentum': opt['momentum'], 'weight_decay': opt['net_wtDcy'], 'lr_mul': 1., 'name': 'netfeatwt'},\n",
    "    {'params': netfeatbias, 'lr': opt['lr'], 'momentum': opt['momentum'], 'weight_decay': 0*opt['net_wtDcy'], 'lr_mul': 2., 'name': 'netfeatbias'},\n",
    "    {'params': net2_weight, 'lr': opt['lr'], 'momentum': opt['momentum'], 'weight_decay': opt['btl_wtDcy'], 'lr_mul': 10., 'name': 'net2wt'},\n",
    "    {'params': net2_bias, 'lr': opt['lr'], 'momentum': opt['momentum'], 'weight_decay': 0*opt['btl_wtDcy'], 'lr_mul': 20., 'name': 'net2bias'}\n",
    "]\n",
    "\n",
    "# optimizer = optim.Adam(net2.parameters(), lr=opt['lr'], betas=opt['betas'], weight_decay=opt['weight_decay'])\n",
    "# optimizer = optim.Adam(sgd_params, betas=opt['betas'])\n",
    "\n",
    "optimizer_2 = optim.SGD(sgd_params)\n",
    "# optimizer_2 = optim.SGD(net2.parameters(), lr=opt['lr'], momentum=opt['momentum'], weight_decay=opt['btl_wtDcy'])\n",
    "\n",
    "lr_sch = None\n",
    "if opt['lr_sch']=='step': lr_sch = optim.lr_scheduler.StepLR(optimizer, 20, opt['lr_sch_gamma'])\n",
    "if opt['lr_sch']=='exponential': lr_sch = optim.lr_scheduler.ExponentialLR(optimizer_2, opt['lr_sch_gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T11:45:30.014832Z",
     "start_time": "2018-04-19T11:45:29.980275Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_validation_acc(cm=False):\n",
    "    tarData = iter(tar_dataloader)\n",
    "    totalCorrects = 0.\n",
    "    if cm: y_preds, y_true = list(), list()\n",
    "    for tarimgs, tarlbls in tarData:\n",
    "        tarimgs = tarimgs.cuda() if opt['use_gpu'] else tarimgs\n",
    "        tarlbls = tarlbls.cuda() if opt['use_gpu'] else tarlbls      \n",
    "        tarimgs = Variable(tarimgs, volatile=True)\n",
    "\n",
    "        feat_ = net(tarimgs)\n",
    "        logits = net2(feat_)\n",
    "\n",
    "        _, preds = torch.max(softmax(logits).data, 1)\n",
    "        totalCorrects += torch.eq(preds, tarlbls).float().sum()\n",
    "        if cm: y_preds.append(preds.cpu().numpy()), y_true.append(tarlbls.cpu().numpy())\n",
    "    valAcc = totalCorrects / opt['tarDataLen']\n",
    "    if cm: return valAcc, y_preds, y_true\n",
    "    return valAcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-19T12:05:38.162938Z",
     "start_time": "2018-04-19T11:45:30.819384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_p:  0.910398960683\n",
      "Epoch: 1, train loss: 2.8967, train acc: 0.3500, validation acc: 0.4151\n",
      "n_p:  0.837535537332\n",
      "Epoch: 2, train loss: 1.3012, train acc: 0.6368, validation acc: 0.4616\n",
      "n_p:  0.776969504241\n",
      "Epoch: 3, train loss: 1.0943, train acc: 0.7025, validation acc: 0.4553\n",
      "n_p:  0.725725807496\n",
      "Epoch: 4, train loss: 0.9430, train acc: 0.7380, validation acc: 0.4868\n",
      "n_p:  0.68173161988\n",
      "Epoch: 5, train loss: 0.8852, train acc: 0.7558, validation acc: 0.5170\n",
      "n_p:  0.643495658493\n",
      "Epoch: 6, train loss: 0.8276, train acc: 0.7700, validation acc: 0.5094\n",
      "n_p:  0.609915886892\n",
      "Epoch: 7, train loss: 0.7323, train acc: 0.7898, validation acc: 0.4981\n",
      "n_p:  0.580159187126\n",
      "Epoch: 8, train loss: 0.6504, train acc: 0.8140, validation acc: 0.5082\n",
      "n_p:  0.55358331165\n",
      "Epoch: 9, train loss: 0.5995, train acc: 0.8293, validation acc: 0.5057\n",
      "n_p:  0.529684678724\n",
      "Epoch: 10, train loss: 0.5537, train acc: 0.8314, validation acc: 0.5107\n",
      "n_p:  0.508062512101\n",
      "Epoch: 11, train loss: 0.5203, train acc: 0.8413, validation acc: 0.5132\n",
      "n_p:  0.488393627875\n",
      "Epoch: 12, train loss: 0.4686, train acc: 0.8605, validation acc: 0.5031\n",
      "n_p:  0.470414339514\n",
      "Epoch: 13, train loss: 0.4833, train acc: 0.8548, validation acc: 0.5484\n",
      "n_p:  0.453907232308\n",
      "Epoch: 14, train loss: 0.4675, train acc: 0.8605, validation acc: 0.5119\n",
      "n_p:  0.438691337651\n",
      "Epoch: 15, train loss: 0.4684, train acc: 0.8789, validation acc: 0.5358\n",
      "n_p:  0.424614725068\n",
      "Epoch: 16, train loss: 0.4605, train acc: 0.8584, validation acc: 0.5044\n",
      "n_p:  0.411548842232\n",
      "Epoch: 17, train loss: 0.4121, train acc: 0.8789, validation acc: 0.4943\n",
      "n_p:  0.399384137858\n",
      "Epoch: 18, train loss: 0.3660, train acc: 0.8864, validation acc: 0.5220\n",
      "n_p:  0.388026639063\n",
      "Epoch: 19, train loss: 0.3673, train acc: 0.8882, validation acc: 0.5321\n",
      "n_p:  0.37739524779\n",
      "Epoch: 20, train loss: 0.3675, train acc: 0.8892, validation acc: 0.5145\n",
      "n_p:  0.367419585202\n",
      "Epoch: 21, train loss: 0.3545, train acc: 0.8878, validation acc: 0.5069\n",
      "n_p:  0.358038258096\n",
      "Epoch: 22, train loss: 0.3140, train acc: 0.8992, validation acc: 0.5321\n",
      "n_p:  0.349197453543\n",
      "Epoch: 23, train loss: 0.3096, train acc: 0.8988, validation acc: 0.5384\n",
      "n_p:  0.340849791129\n",
      "Epoch: 24, train loss: 0.2975, train acc: 0.9081, validation acc: 0.5321\n",
      "n_p:  0.33295337907\n",
      "Epoch: 25, train loss: 0.2918, train acc: 0.9084, validation acc: 0.5497\n",
      "n_p:  0.325471032966\n",
      "Epoch: 26, train loss: 0.2709, train acc: 0.9162, validation acc: 0.5421\n",
      "n_p:  0.318369625258\n",
      "Epoch: 27, train loss: 0.2867, train acc: 0.9077, validation acc: 0.5157\n",
      "n_p:  0.311619540435\n",
      "Epoch: 28, train loss: 0.2511, train acc: 0.9212, validation acc: 0.5157\n",
      "n_p:  0.305194216374\n",
      "Epoch: 29, train loss: 0.2436, train acc: 0.9201, validation acc: 0.5371\n",
      "n_p:  0.299069756244\n",
      "Epoch: 30, train loss: 0.2427, train acc: 0.9208, validation acc: 0.5208\n",
      "n_p:  0.293224598578\n",
      "Epoch: 31, train loss: 0.2480, train acc: 0.9215, validation acc: 0.5522\n",
      "n_p:  0.287639235518\n",
      "Epoch: 32, train loss: 0.2518, train acc: 0.9208, validation acc: 0.5270\n",
      "n_p:  0.282295971197\n",
      "Epoch: 33, train loss: 0.2368, train acc: 0.9269, validation acc: 0.5572\n",
      "n_p:  0.277178713699\n",
      "Epoch: 34, train loss: 0.2083, train acc: 0.9354, validation acc: 0.5459\n",
      "n_p:  0.272272795256\n",
      "Epoch: 35, train loss: 0.2248, train acc: 0.9269, validation acc: 0.5296\n",
      "n_p:  0.267564816275\n",
      "Epoch: 36, train loss: 0.2119, train acc: 0.9304, validation acc: 0.5321\n",
      "n_p:  0.263042509582\n",
      "Epoch: 37, train loss: 0.2015, train acc: 0.9379, validation acc: 0.5396\n",
      "n_p:  0.258694621872\n",
      "Epoch: 38, train loss: 0.2767, train acc: 0.9379, validation acc: 0.5384\n",
      "n_p:  0.254510809851\n",
      "Epoch: 39, train loss: 0.2819, train acc: 0.9120, validation acc: 0.5069\n",
      "n_p:  0.250481548996\n",
      "Epoch: 40, train loss: 0.2090, train acc: 0.9365, validation acc: 0.5157\n",
      "n_p:  0.24659805315\n",
      "Epoch: 41, train loss: 0.1950, train acc: 0.9389, validation acc: 0.5119\n",
      "n_p:  0.242852203489\n",
      "Epoch: 42, train loss: 0.2201, train acc: 0.9343, validation acc: 0.5421\n",
      "n_p:  0.239236485591\n",
      "Epoch: 43, train loss: 0.2007, train acc: 0.9389, validation acc: 0.5258\n",
      "n_p:  0.235743933552\n",
      "Epoch: 44, train loss: 0.1867, train acc: 0.9425, validation acc: 0.5472\n",
      "n_p:  0.232368080243\n",
      "Epoch: 45, train loss: 0.1979, train acc: 0.9372, validation acc: 0.5308\n",
      "n_p:  0.229102912911\n",
      "Epoch: 46, train loss: 0.1805, train acc: 0.9436, validation acc: 0.5623\n",
      "n_p:  0.225942833495\n",
      "Epoch: 47, train loss: 0.1774, train acc: 0.9436, validation acc: 0.5396\n",
      "n_p:  0.222882623044\n",
      "Epoch: 48, train loss: 0.1708, train acc: 0.9464, validation acc: 0.5358\n",
      "n_p:  0.219917409779\n",
      "Epoch: 49, train loss: 0.1802, train acc: 0.9446, validation acc: 0.5497\n",
      "n_p:  0.217042640348\n",
      "Epoch: 50, train loss: 0.2097, train acc: 0.9446, validation acc: 0.5597\n",
      "n_p:  0.214254053912\n",
      "Epoch: 51, train loss: 0.1849, train acc: 0.9407, validation acc: 0.5296\n",
      "n_p:  0.211547658749\n",
      "Epoch: 52, train loss: 0.1606, train acc: 0.9524, validation acc: 0.5321\n",
      "n_p:  0.208919711073\n",
      "Epoch: 53, train loss: 0.1796, train acc: 0.9453, validation acc: 0.5384\n",
      "n_p:  0.206366695852\n",
      "Epoch: 54, train loss: 0.1712, train acc: 0.9464, validation acc: 0.5258\n",
      "n_p:  0.203885309382\n",
      "Epoch: 55, train loss: 0.1626, train acc: 0.9507, validation acc: 0.5220\n",
      "n_p:  0.20147244345\n",
      "Epoch: 56, train loss: 0.1686, train acc: 0.9507, validation acc: 0.5283\n",
      "n_p:  0.199125170911\n",
      "Epoch: 57, train loss: 0.2068, train acc: 0.9468, validation acc: 0.5208\n",
      "n_p:  0.196840732524\n",
      "Epoch: 58, train loss: 0.1799, train acc: 0.9404, validation acc: 0.5447\n",
      "n_p:  0.194616524945\n",
      "Epoch: 59, train loss: 0.1677, train acc: 0.9492, validation acc: 0.5396\n",
      "n_p:  0.19245008973\n",
      "Epoch: 60, train loss: 0.1475, train acc: 0.9574, validation acc: 0.5409\n",
      "n_p:  0.190339103271\n",
      "Epoch: 61, train loss: 0.1402, train acc: 0.9556, validation acc: 0.5245\n",
      "n_p:  0.188281367563\n",
      "Epoch: 62, train loss: 0.1651, train acc: 0.9503, validation acc: 0.5296\n",
      "n_p:  0.186274801726\n",
      "Epoch: 63, train loss: 0.1438, train acc: 0.9563, validation acc: 0.5371\n",
      "n_p:  0.184317434211\n",
      "Epoch: 64, train loss: 0.1261, train acc: 0.9578, validation acc: 0.5447\n",
      "n_p:  0.182407395622\n",
      "Epoch: 65, train loss: 0.1409, train acc: 0.9542, validation acc: 0.5258\n",
      "n_p:  0.180542912107\n",
      "Epoch: 66, train loss: 0.1512, train acc: 0.9556, validation acc: 0.5195\n",
      "n_p:  0.178722299253\n",
      "Epoch: 67, train loss: 0.1362, train acc: 0.9599, validation acc: 0.5585\n",
      "n_p:  0.176943956448\n",
      "Epoch: 68, train loss: 0.1299, train acc: 0.9585, validation acc: 0.5660\n",
      "n_p:  0.175206361673\n",
      "Epoch: 69, train loss: 0.1398, train acc: 0.9588, validation acc: 0.5522\n",
      "n_p:  0.173508066677\n",
      "Epoch: 70, train loss: 0.1331, train acc: 0.9585, validation acc: 0.5358\n",
      "n_p:  0.1718476925\n",
      "Epoch: 71, train loss: 0.1370, train acc: 0.9546, validation acc: 0.5333\n",
      "n_p:  0.170223925335\n",
      "Epoch: 72, train loss: 0.1234, train acc: 0.9624, validation acc: 0.5484\n",
      "n_p:  0.16863551267\n",
      "Epoch: 73, train loss: 0.1340, train acc: 0.9578, validation acc: 0.5258\n",
      "n_p:  0.167081259717\n",
      "Epoch: 74, train loss: 0.1351, train acc: 0.9620, validation acc: 0.5384\n",
      "n_p:  0.165560026076\n",
      "Epoch: 75, train loss: 0.1353, train acc: 0.9599, validation acc: 0.5270\n"
     ]
    }
   ],
   "source": [
    "p = np.linspace(float(1./opt['p_lr_decay']),1,opt['p_lr_decay'])\n",
    "\n",
    "for epoch in range(opt['epochs']):\n",
    "    srcData = iter(src_dataloader)\n",
    "    totalCorrects = 0.\n",
    "    totalClsLoss = 0.\n",
    "#     experiment.log_current_epoch(epoch)\n",
    "    \n",
    "    n_p = opt['n0'] / pow((1. + opt['alpha'] * p[epoch]), (opt['beta']))\n",
    "    print(\"n_p: \", n_p)\n",
    "    for param_group in optimizer_2.param_groups:\n",
    "        param_group['lr'] = opt['lr'] * param_group['lr_mul'] * n_p\n",
    "        \n",
    "    for srcimgs, srclbls in srcData:\n",
    "        srcimgs = srcimgs.cuda() if opt['use_gpu'] else srcimgs\n",
    "        srclbls = srclbls.cuda() if opt['use_gpu'] else srclbls\n",
    "        srcimgs, srclbls = Variable(srcimgs), Variable(srclbls)\n",
    "        \n",
    "        feat_ = net(srcimgs)\n",
    "        logits = net2(feat_)\n",
    "        \n",
    "        clsloss = criterion(logits, srclbls)\n",
    "        totalClsLoss += clsloss.data[0] * opt['batchSize']\n",
    "        \n",
    "        _, preds = torch.max(softmax(logits).data, 1)\n",
    "        totalCorrects += torch.eq(preds, srclbls.data).float().sum()\n",
    "               \n",
    "        optimizer_2.zero_grad()\n",
    "        clsloss.backward()\n",
    "        optimizer_2.step()\n",
    "        \n",
    "        if lr_sch: lr_sch.step()\n",
    "        \n",
    "    srcAcc = totalCorrects / opt['srcDataLen']\n",
    "    srcLoss = totalClsLoss / opt['srcDataLen']\n",
    "    valAcc = get_validation_acc()\n",
    "#     experiment.log_metric(\"src_clsLoss\", srcLoss, step=epoch)\n",
    "#     experiment.log_metric(\"src_clsAcc\", srcAcc, step=epoch)\n",
    "#     experiment.log_metric('val_accuracy', valAcc, step=epoch)\n",
    "#     experiment.log_epoch_end(epoch)\n",
    "    print(\"Epoch: {}, train loss: {:.4f}, train acc: {:.4f}, validation acc: {:.4f}\".\n",
    "          format(epoch+1, srcLoss, srcAcc, valAcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "valAcc, y_preds, y_true = get_validation_acc(cm=True)\n",
    "\n",
    "y_preds = [d for sublist in y_preds for d in sublist]\n",
    "y_true = [d for sublist in y_true for d in sublist]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_preds)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure(figsize=(20,20))\n",
    "utils.plot_confusion_matrix(cm, classes=src_dataset.classes, normalize=False)\n",
    "plt.show()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
