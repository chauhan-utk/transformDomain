{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code taken from here : http://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from config import domainData\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GRL(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        x = 1 * x\n",
    "        return x\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        grad_output = -1 * grad_output\n",
    "        return grad_output\n",
    "grl = GRL.apply # create alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "use_gpu = True and torch.cuda.is_available()\n",
    "train_dir = domainData['amazon'] # 'amazon', 'dslr', 'webcam'\n",
    "val_dir = domainData['webcam']\n",
    "\n",
    "image_datasets = {'train' : datasets.ImageFolder(train_dir,\n",
    "                                          data_transforms['train']),\n",
    "                  'val' : datasets.ImageFolder(val_dir,\n",
    "                                          data_transforms['val'])\n",
    "                 }\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    inp = inp.numpy().transpose((1,2,0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, clscriterion, dmncriterion, srcoptimizer, taroptimizer, \n",
    "                srcscheduler, tarscheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # 0 - source 1 - target\n",
    "        srcdata = iter(dataloaders['train'])\n",
    "        tardata = iter(dataloaders['val'])\n",
    "        tardata = itertools.cycle(tardata) # generating target data without hassle\n",
    "        \n",
    "        model.train() # training mode\n",
    "        srcscheduler.step()\n",
    "        tarscheduler.step()\n",
    "\n",
    "        running_clsloss = 0.0\n",
    "        running_dmnloss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data in srcdata:\n",
    "            # get the inputs\n",
    "            srcinps, srclbls = data\n",
    "            tarinps, tarlbls = next(tardata)\n",
    "            \n",
    "            # wrap them in Variable\n",
    "            \n",
    "            if use_gpu:\n",
    "                srcinps = Variable(srcinps.cuda())\n",
    "                srclbls = Variable(srclbls.cuda())\n",
    "                tarinps = Variable(tarinps.cuda())\n",
    "                tarlbls = Variable(tarlbls.cuda())\n",
    "            else:\n",
    "                srcinps, srclbls = Variable(srcinps), Variable(srclbls)\n",
    "                tarinps, tarlbls = Variable(tarinps), Variable(tarlbls)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            srcoptimizer.zero_grad()\n",
    "\n",
    "            # source data\n",
    "            model.is_source = True\n",
    "            srcoutput = model(srcinps)\n",
    "            dmnlbls = torch.LongTensor(srcoutput[0].size(0)).zero_()\n",
    "            if use_gpu:\n",
    "                dmnlbls = dmnlbls.cuda()\n",
    "            dmnlbls = Variable(dmnlbls, requires_grad=False)\n",
    "            _, preds = torch.max(srcoutput[1].data, 1)\n",
    "            clsloss = clscriterion(srcoutput[1], srclbls)\n",
    "#             print(\"lblb: \", srcoutput[0])\n",
    "#             print(\"srclbls: \", srclbls)\n",
    "            dmnloss = dmncriterion(srcoutput[0], dmnlbls)\n",
    "            loss = clsloss + dmnloss\n",
    "            \n",
    "            loss.backward()\n",
    "            srcoptimizer.step()\n",
    "            \n",
    "            taroptimizer.zero_grad()\n",
    "            \n",
    "            # target data\n",
    "            model.is_source = False\n",
    "            taroutput = model(tarinps)\n",
    "            dmnlbls = torch.ones(taroutput[0].size(0)).long()\n",
    "            if use_gpu:\n",
    "                dmnlbls = dmnlbls.cuda()\n",
    "            dmnlbls = Variable(dmnlbls, requires_grad=False)\n",
    "            dmnloss2 = dmncriterion(taroutput[0], dmnlbls)\n",
    "            dmnloss2.backward()\n",
    "            taroptimizer.step()\n",
    "            \n",
    "            # statistics\n",
    "            running_clsloss += clsloss.data[0] * srcinps.size(0)\n",
    "            running_dmnloss += dmnloss.data[0] * srcinps.size(0)\n",
    "            running_dmnloss += dmnloss2.data[0] * tarinps.size(0)\n",
    "            running_corrects += torch.sum(preds == srclbls.data)\n",
    "            \n",
    "\n",
    "        epoch_clsloss = running_clsloss / dataset_sizes['train']\n",
    "        epoch_dmnloss = running_dmnloss / (dataset_sizes['train'] + dataset_sizes['val'])\n",
    "        epoch_acc = running_corrects / dataset_sizes['train']\n",
    "\n",
    "        print('Classification Loss: {:.4f} Domain Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "        epoch_clsloss, epoch_dmnloss, epoch_acc))\n",
    "        \n",
    "        if best_acc < epoch_acc:\n",
    "            best_acc = epoch_acc        \n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GRLModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRLModel, self).__init__()\n",
    "        resnet18 = models.resnet18(pretrained=True)\n",
    "        self.features = nn.Sequential(*list(resnet18.children())[:-1]) # get the feature extractor\n",
    "        self.transform = nn.Sequential(nn.Linear(512,64), nn.ReLU(inplace=True), \n",
    "                                       nn.Linear(64,512), nn.ReLU(inplace=True))\n",
    "        self.is_source = True\n",
    "        self.grl = nn.Sequential(\n",
    "            nn.Linear(512,64), nn.ReLU(inplace=True),\n",
    "            nn.Linear(64,2), nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.classifier = nn.Linear(512,31)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            x = self.features(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            if not self.is_source:\n",
    "                x = self.transform(x)\n",
    "            x_ = grl(x)\n",
    "            # x_ = x_.view(x_.size(0), -1)\n",
    "            out1 = self.grl(x_)\n",
    "            # x = x.view(x.size(0), -1)\n",
    "            out2 = self.classifier(x)        \n",
    "            return out1, out2\n",
    "        else:\n",
    "            x = self.features(x)\n",
    "            out = self.classifier(x.view(x.size(0),-1))\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ft = GRLModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ft.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "clscriterion = nn.CrossEntropyLoss()\n",
    "dmncriterion = nn.CrossEntropyLoss()\n",
    "\n",
    "src_params = []\n",
    "src_params += list(model_ft.features.parameters())\n",
    "src_params += list(model_ft.classifier.parameters())\n",
    "src_params += list(model_ft.grl.parameters())\n",
    "srcoptimizer = optim.SGD(src_params, lr=0.001, momentum=0.9) # optimize all parameters\n",
    "param_group = []\n",
    "param_group += list(model_ft.features.parameters())\n",
    "param_group += list(model_ft.transform.parameters())\n",
    "param_group += list(model_ft.grl.parameters())\n",
    "taroptimizer = optim.SGD(param_group, lr=0.01, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "src_lr_scheduler = lr_scheduler.StepLR(srcoptimizer, step_size=7, gamma=0.1)\n",
    "tar_lr_scheduler = lr_scheduler.StepLR(taroptimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model(model_ft, clscriterion, dmncriterion, srcoptimizer, taroptimizer, src_lr_scheduler, tar_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model_ft, criterion, save_model=False, save_name=None):\n",
    "    data_iter = iter(dataloaders['val'])\n",
    "    model_ft.eval()\n",
    "    acc_val = 0\n",
    "    for data in data_iter:\n",
    "        img, lbl = data\n",
    "        if use_gpu:\n",
    "            img = img.cuda()\n",
    "            lbl = lbl.cuda()\n",
    "        img = Variable(img)\n",
    "        lbl = Variable(lbl)\n",
    "        \n",
    "        out = model_ft(img)\n",
    "        _, preds = torch.max(out.data, 1)\n",
    "        loss = criterion(out, lbl)\n",
    "        acc_val += torch.sum(preds == lbl.data)\n",
    "    acc = acc_val / dataset_sizes['val']\n",
    "    print(\"validation accuracy: {:.4f}\".format(acc))\n",
    "    if save_model:\n",
    "        torch.save(model_ft.state_dict(), save_name)\n",
    "    return\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = \"grl_model_with_transform.pth\"\n",
    "test_model(model_ft, clscriterion, True, save_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
